{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header-cell",
   "metadata": {},
   "source": [
    "# Statistical Analysis Template for Medical Research\n",
    "\n",
    "**Project:** [Enter project name]\n",
    "\n",
    "**Principal Investigator:** [Enter PI name]\n",
    "\n",
    "**Statistician:** [Enter statistician name]\n",
    "\n",
    "**Date:** [Enter date]\n",
    "\n",
    "**Version:** 1.0\n",
    "\n",
    "---\n",
    "\n",
    "## Research Questions\n",
    "\n",
    "**Primary Research Question:**\n",
    "- [State primary research question]\n",
    "\n",
    "**Secondary Research Questions:**\n",
    "- [List secondary research questions]\n",
    "\n",
    "**Hypotheses:**\n",
    "- **H₀:** [Null hypothesis]\n",
    "- **H₁:** [Alternative hypothesis]\n",
    "\n",
    "---\n",
    "\n",
    "## Study Design and Variables\n",
    "\n",
    "**Study Design:** [e.g., RCT, cohort, case-control, cross-sectional]\n",
    "\n",
    "**Primary Outcome:** [Define primary outcome variable]\n",
    "\n",
    "**Secondary Outcomes:** [List secondary outcomes]\n",
    "\n",
    "**Predictors/Exposures:** [List key variables]\n",
    "\n",
    "**Confounders:** [List potential confounding variables]\n",
    "\n",
    "**Sample Size Justification:** [Include power calculation]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "setup-cell",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading\n",
    "\n",
    "Load required packages and import the medical statistics toolkit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import medical statistics toolkit\n",
    "from medical_stats_toolkit import (\n",
    "    DescriptiveStatistics, HypothesisTests, EffectSizes, PowerAnalysis,\n",
    "    SurvivalAnalysis, MetaAnalysis, MLEvaluationMetrics, \n",
    "    MedicalVisualizations, MultipleComparisons, load_data, generate_sample_data\n",
    ")\n",
    "\n",
    "# Set visualization parameters\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "plt.rcParams['font.size'] = 12\n",
    "\n",
    "print(\"Medical Statistics Toolkit loaded successfully!\")\n",
    "print(\"Notebook template ready for analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-loading",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Load your dataset and perform initial inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "# Replace with your actual data file path\n",
    "# data = load_data('path/to/your/data.csv')\n",
    "\n",
    "# For demonstration, we'll generate sample medical data\n",
    "data = generate_sample_data(n_samples=300, seed=42)\n",
    "\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "display(data.head())\n",
    "\n",
    "print(\"\\nDataset info:\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-quality",
   "metadata": {},
   "source": [
    "## 2. Data Quality Assessment\n",
    "\n",
    "Examine data quality, missing values, and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "missing-values",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_data = data.isnull().sum()\n",
    "missing_percent = (missing_data / len(data)) * 100\n",
    "\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing_Count': missing_data,\n",
    "    'Missing_Percent': missing_percent\n",
    "}).sort_values('Missing_Percent', ascending=False)\n",
    "\n",
    "print(\"Missing Data Summary:\")\n",
    "print(missing_summary[missing_summary['Missing_Count'] > 0])\n",
    "\n",
    "# Visualize missing data pattern\n",
    "if missing_data.sum() > 0:\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(data.isnull(), cbar=True, yticklabels=False, cmap='viridis')\n",
    "    plt.title('Missing Data Pattern')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outliers",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify potential outliers for continuous variables\n",
    "continuous_vars = data.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "print(\"Outlier Detection (values beyond 3 SD):\")\n",
    "for var in continuous_vars:\n",
    "    if var != 'patient_id':  # Skip ID variables\n",
    "        mean_val = data[var].mean()\n",
    "        std_val = data[var].std()\n",
    "        outliers = data[(data[var] < mean_val - 3*std_val) | (data[var] > mean_val + 3*std_val)]\n",
    "        print(f\"{var}: {len(outliers)} potential outliers ({len(outliers)/len(data)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "descriptive-stats",
   "metadata": {},
   "source": [
    "## 3. Descriptive Statistics\n",
    "\n",
    "Generate comprehensive descriptive statistics for all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuous-descriptives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for continuous variables\n",
    "print(\"CONTINUOUS VARIABLES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "continuous_vars = ['age', 'continuous_outcome', 'survival_time']\n",
    "\n",
    "descriptive_results = {}\n",
    "for var in continuous_vars:\n",
    "    if var in data.columns:\n",
    "        stats = DescriptiveStatistics.summary_statistics(data[var])\n",
    "        descriptive_results[var] = stats\n",
    "        \n",
    "        print(f\"\\n{var.upper()}:\")\n",
    "        print(f\"  n = {stats['n']}\")\n",
    "        print(f\"  Missing = {stats['missing']}\")\n",
    "        print(f\"  Mean ± SD = {stats['mean']:.2f} ± {stats['std']:.2f}\")\n",
    "        print(f\"  95% CI = [{stats['ci_lower']:.2f}, {stats['ci_upper']:.2f}]\")\n",
    "        print(f\"  Median [IQR] = {stats['median']:.2f} [{stats['q1']:.2f}, {stats['q3']:.2f}]\")\n",
    "        print(f\"  Range = [{stats['min']:.2f}, {stats['max']:.2f}]\")\n",
    "        \n",
    "        # Normality test\n",
    "        if not np.isnan(stats['shapiro_p']):\n",
    "            normality = \"Normal\" if stats['normal_distribution'] else \"Non-normal\"\n",
    "            print(f\"  Distribution = {normality} (Shapiro-Wilk p = {stats['shapiro_p']:.3f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "categorical-descriptives",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics for categorical variables\n",
    "print(\"\\nCATEGORICAL VARIABLES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "categorical_vars = ['gender', 'diabetes', 'treatment', 'outcome', 'event_observed']\n",
    "\n",
    "for var in categorical_vars:\n",
    "    if var in data.columns:\n",
    "        cat_stats = DescriptiveStatistics.categorical_summary(data[var])\n",
    "        \n",
    "        print(f\"\\n{var.upper()}:\")\n",
    "        for _, row in cat_stats.iterrows():\n",
    "            print(f\"  {row['category']}: {row['count']} ({row['percentage']:.1f}%) \"\n",
    "                  f\"[95% CI: {row['ci_lower']:.1f}%, {row['ci_upper']:.1f}%]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visualizations",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis\n",
    "\n",
    "Create visualizations to understand data distribution and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distribution-plots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution plots for continuous variables\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "continuous_vars = ['age', 'continuous_outcome', 'survival_time']\n",
    "\n",
    "for i, var in enumerate(continuous_vars):\n",
    "    if var in data.columns and i < len(axes):\n",
    "        # Histogram with density curve\n",
    "        data[var].hist(bins=30, alpha=0.7, ax=axes[i], density=True)\n",
    "        data[var].plot(kind='density', ax=axes[i], color='red', linewidth=2)\n",
    "        axes[i].set_title(f'Distribution of {var.title()}')\n",
    "        axes[i].set_ylabel('Density')\n",
    "\n",
    "# Remove empty subplot\n",
    "if len(continuous_vars) < len(axes):\n",
    "    fig.delaxes(axes[-1])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boxplots",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots by groups\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "# Age by treatment group\n",
    "data.boxplot(column='age', by='treatment', ax=axes[0])\n",
    "axes[0].set_title('Age by Treatment Group')\n",
    "axes[0].set_xlabel('Treatment (0=Control, 1=Active)')\n",
    "\n",
    "# Continuous outcome by treatment\n",
    "data.boxplot(column='continuous_outcome', by='treatment', ax=axes[1])\n",
    "axes[1].set_title('Continuous Outcome by Treatment Group')\n",
    "axes[1].set_xlabel('Treatment (0=Control, 1=Active)')\n",
    "\n",
    "# Continuous outcome by diabetes status\n",
    "data.boxplot(column='continuous_outcome', by='diabetes', ax=axes[2])\n",
    "axes[2].set_title('Continuous Outcome by Diabetes Status')\n",
    "axes[2].set_xlabel('Diabetes (0=No, 1=Yes)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correlation-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix for continuous variables\n",
    "numeric_cols = data.select_dtypes(include=[np.number]).columns\n",
    "correlation_matrix = data[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "mask = np.triu(np.ones_like(correlation_matrix, dtype=bool))\n",
    "sns.heatmap(correlation_matrix, mask=mask, annot=True, cmap='coolwarm', center=0,\n",
    "            square=True, fmt='.2f', cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-analysis",
   "metadata": {},
   "source": [
    "## 5. Primary Analysis\n",
    "\n",
    "Conduct the main statistical analysis to address primary research questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-outcome-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Compare continuous outcome between treatment groups\n",
    "print(\"PRIMARY ANALYSIS: Treatment Effect on Continuous Outcome\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Separate groups\n",
    "treatment_group = data[data['treatment'] == 1]['continuous_outcome'].dropna()\n",
    "control_group = data[data['treatment'] == 0]['continuous_outcome'].dropna()\n",
    "\n",
    "# Check normality assumption\n",
    "treatment_normal = stats.shapiro(treatment_group)[1] > 0.05\n",
    "control_normal = stats.shapiro(control_group)[1] > 0.05\n",
    "\n",
    "print(f\"Treatment group normality: {treatment_normal} (p = {stats.shapiro(treatment_group)[1]:.3f})\")\n",
    "print(f\"Control group normality: {control_normal} (p = {stats.shapiro(control_group)[1]:.3f})\")\n",
    "\n",
    "# Parametric test (if assumptions met)\n",
    "if treatment_normal and control_normal:\n",
    "    print(\"\\nUsing parametric test (Independent samples t-test):\")\n",
    "    t_result = HypothesisTests.t_test_independent(treatment_group, control_group)\n",
    "    \n",
    "    print(f\"T-statistic: {t_result['t_statistic']:.4f}\")\n",
    "    print(f\"P-value: {t_result['p_value']:.6f}\")\n",
    "    print(f\"Degrees of freedom: {t_result['degrees_of_freedom']:.0f}\")\n",
    "    print(f\"Cohen's d: {t_result['cohens_d']:.4f}\")\n",
    "    print(f\"Result: {t_result['interpretation']}\")\n",
    "    \n",
    "    # Group statistics\n",
    "    print(f\"\\nTreatment group: Mean = {t_result['group1_stats']['mean']:.2f} ± {t_result['group1_stats']['std']:.2f}\")\n",
    "    print(f\"Control group: Mean = {t_result['group2_stats']['mean']:.2f} ± {t_result['group2_stats']['std']:.2f}\")\n",
    "    print(f\"Mean difference: {t_result['group1_stats']['mean'] - t_result['group2_stats']['mean']:.2f}\")\n",
    "\n",
    "# Non-parametric alternative\n",
    "print(\"\\nNon-parametric test (Mann-Whitney U test):\")\n",
    "mw_result = HypothesisTests.mann_whitney_u(treatment_group, control_group)\n",
    "print(f\"U-statistic: {mw_result['u_statistic']:.0f}\")\n",
    "print(f\"P-value: {mw_result['p_value']:.6f}\")\n",
    "print(f\"Effect size (r): {mw_result['effect_size_r']:.4f}\")\n",
    "print(f\"Treatment median: {mw_result['median_group1']:.2f}\")\n",
    "print(f\"Control median: {mw_result['median_group2']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "binary-outcome-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Analyze binary outcome (chi-square test)\n",
    "print(\"\\nBINARY OUTCOME ANALYSIS: Treatment Effect on Binary Outcome\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create contingency table\n",
    "contingency_table = pd.crosstab(data['treatment'], data['outcome'], margins=True)\n",
    "print(\"Contingency Table:\")\n",
    "print(contingency_table)\n",
    "\n",
    "# Chi-square test\n",
    "chi2_result = HypothesisTests.chi_square_test(contingency_table.iloc[:-1, :-1])\n",
    "print(f\"\\nChi-square statistic: {chi2_result['chi2_statistic']:.4f}\")\n",
    "print(f\"P-value: {chi2_result['p_value']:.6f}\")\n",
    "print(f\"Degrees of freedom: {chi2_result['degrees_of_freedom']}\")\n",
    "print(f\"Cramer's V: {chi2_result['cramers_v']:.4f}\")\n",
    "\n",
    "# Effect sizes for 2x2 table\n",
    "if contingency_table.shape == (3, 3):  # Including margins\n",
    "    table_2x2 = contingency_table.iloc[:-1, :-1].values\n",
    "    a, b = table_2x2[0, 1], table_2x2[0, 0]  # Treatment: outcome=1, outcome=0\n",
    "    c, d = table_2x2[1, 1], table_2x2[1, 0]  # Control: outcome=1, outcome=0\n",
    "    \n",
    "    or_result = EffectSizes.odds_ratio_ci(a, b, c, d)\n",
    "    rr_result = EffectSizes.relative_risk_ci(a, b, c, d)\n",
    "    \n",
    "    print(f\"\\nOdds Ratio: {or_result['odds_ratio']:.4f} [95% CI: {or_result['ci_lower']:.4f}, {or_result['ci_upper']:.4f}]\")\n",
    "    print(f\"Relative Risk: {rr_result['relative_risk']:.4f} [95% CI: {rr_result['ci_lower']:.4f}, {rr_result['ci_upper']:.4f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "secondary-analysis",
   "metadata": {},
   "source": [
    "## 6. Secondary Analyses\n",
    "\n",
    "Perform additional analyses for secondary outcomes and exploratory questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subgroup-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subgroup analysis by diabetes status\n",
    "print(\"SUBGROUP ANALYSIS: Treatment Effect by Diabetes Status\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "subgroup_results = []\n",
    "\n",
    "for diabetes_status in [0, 1]:\n",
    "    subgroup_data = data[data['diabetes'] == diabetes_status]\n",
    "    treatment_sub = subgroup_data[subgroup_data['treatment'] == 1]['continuous_outcome'].dropna()\n",
    "    control_sub = subgroup_data[subgroup_data['treatment'] == 0]['continuous_outcome'].dropna()\n",
    "    \n",
    "    if len(treatment_sub) > 5 and len(control_sub) > 5:  # Minimum sample size check\n",
    "        t_result = HypothesisTests.t_test_independent(treatment_sub, control_sub)\n",
    "        \n",
    "        diabetes_label = \"No Diabetes\" if diabetes_status == 0 else \"Diabetes\"\n",
    "        print(f\"\\n{diabetes_label}:\")\n",
    "        print(f\"  Sample sizes: Treatment n={len(treatment_sub)}, Control n={len(control_sub)}\")\n",
    "        print(f\"  Mean difference: {t_result['group1_stats']['mean'] - t_result['group2_stats']['mean']:.2f}\")\n",
    "        print(f\"  T-statistic: {t_result['t_statistic']:.4f}\")\n",
    "        print(f\"  P-value: {t_result['p_value']:.6f}\")\n",
    "        print(f\"  Cohen's d: {t_result['cohens_d']:.4f}\")\n",
    "        \n",
    "        subgroup_results.append({\n",
    "            'subgroup': diabetes_label,\n",
    "            'p_value': t_result['p_value'],\n",
    "            'effect_size': t_result['cohens_d']\n",
    "        })\n",
    "\n",
    "# Store p-values for multiple comparisons correction\n",
    "if subgroup_results:\n",
    "    subgroup_p_values = [result['p_value'] for result in subgroup_results]\n",
    "    \n",
    "    # Apply Bonferroni correction\n",
    "    correction_result = MultipleComparisons.adjust_p_values(subgroup_p_values, method='bonferroni')\n",
    "    \n",
    "    print(\"\\nMultiple Comparisons Correction (Bonferroni):\")\n",
    "    for i, result in enumerate(subgroup_results):\n",
    "        print(f\"{result['subgroup']}: Adjusted p = {correction_result['adjusted_p_values'][i]:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regression-analysis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiple regression analysis\n",
    "print(\"\\nMULTIPLE REGRESSION ANALYSIS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Prepare data for regression\n",
    "regression_data = data[['continuous_outcome', 'treatment', 'age', 'gender', 'diabetes']].dropna()\n",
    "\n",
    "# Define variables\n",
    "y = regression_data['continuous_outcome']\n",
    "X = regression_data[['treatment', 'age', 'gender', 'diabetes']]\n",
    "X = sm.add_constant(X)  # Add intercept\n",
    "\n",
    "# Fit model\n",
    "model = sm.OLS(y, X).fit()\n",
    "\n",
    "print(\"Multiple Linear Regression Results:\")\n",
    "print(model.summary())\n",
    "\n",
    "# Extract key results\n",
    "treatment_coef = model.params['treatment']\n",
    "treatment_pvalue = model.pvalues['treatment']\n",
    "treatment_ci = model.conf_int().loc['treatment']\n",
    "\n",
    "print(f\"\\nTreatment effect (adjusted):\")\n",
    "print(f\"Coefficient: {treatment_coef:.4f} [95% CI: {treatment_ci[0]:.4f}, {treatment_ci[1]:.4f}]\")\n",
    "print(f\"P-value: {treatment_pvalue:.6f}\")\n",
    "print(f\"R-squared: {model.rsquared:.4f}\")\n",
    "print(f\"Adjusted R-squared: {model.rsquared_adj:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "survival-analysis",
   "metadata": {},
   "source": [
    "## 7. Survival Analysis (if applicable)\n",
    "\n",
    "Perform survival analysis if time-to-event data is available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kaplan-meier",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kaplan-Meier survival analysis\n",
    "print(\"SURVIVAL ANALYSIS\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Overall survival\n",
    "km_overall = SurvivalAnalysis.kaplan_meier_analysis(\n",
    "    data['survival_time'], \n",
    "    data['event_observed']\n",
    ")\n",
    "\n",
    "if 'error' not in km_overall:\n",
    "    print(f\"Overall median survival: {km_overall['median_survival']:.2f} time units\")\n",
    "    \n",
    "    # Survival by treatment group\n",
    "    km_by_treatment = SurvivalAnalysis.kaplan_meier_analysis(\n",
    "        data['survival_time'], \n",
    "        data['event_observed'],\n",
    "        groups=data['treatment']\n",
    "    )\n",
    "    \n",
    "    if 'logrank_test' in km_by_treatment:\n",
    "        logrank = km_by_treatment['logrank_test']\n",
    "        print(f\"\\nLog-rank test p-value: {logrank['p_value']:.6f}\")\n",
    "        print(f\"Significant difference: {logrank['significant']}\")\n",
    "        \n",
    "        # Median survival by group\n",
    "        for group in [0, 1]:\n",
    "            if group in km_by_treatment:\n",
    "                median_surv = km_by_treatment[group]['median_survival']\n",
    "                group_label = \"Control\" if group == 0 else \"Treatment\"\n",
    "                print(f\"{group_label} median survival: {median_surv:.2f} time units\")\n",
    "    \n",
    "    # Create Kaplan-Meier plot\n",
    "    km_plot = MedicalVisualizations.kaplan_meier_plot(\n",
    "        data['survival_time'], \n",
    "        data['event_observed'],\n",
    "        groups=data['treatment'],\n",
    "        title=\"Kaplan-Meier Survival Curves by Treatment Group\"\n",
    "    )\n",
    "    \n",
    "    if km_plot:\n",
    "        plt.show()\nelse:\n",
    "    print(km_overall['error'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "power-analysis",
   "metadata": {},
   "source": [
    "## 8. Power Analysis and Sample Size\n",
    "\n",
    "Evaluate the statistical power of your analyses and calculate required sample sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "post-hoc-power",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-hoc power analysis\n",
    "print(\"POST-HOC POWER ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "# Calculate observed effect size from primary analysis\n",
    "treatment_group = data[data['treatment'] == 1]['continuous_outcome'].dropna()\n",
    "control_group = data[data['treatment'] == 0]['continuous_outcome'].dropna()\n",
    "\n",
    "observed_effect_size = EffectSizes.cohens_d(treatment_group, control_group)\n",
    "\n",
    "# Calculate achieved power\n",
    "achieved_power = PowerAnalysis.power_t_test_independent(\n",
    "    effect_size=observed_effect_size,\n",
    "    n1=len(treatment_group),\n",
    "    n2=len(control_group),\n",
    "    alpha=0.05\n",
    ")\n",
    "\n",
    "print(f\"Observed effect size (Cohen's d): {observed_effect_size:.4f}\")\n",
    "print(f\"Achieved statistical power: {achieved_power:.4f} ({achieved_power*100:.1f}%)\")\n",
    "print(f\"Sample sizes: Treatment n={len(treatment_group)}, Control n={len(control_group)}\")\n",
    "\n",
    "# Sample size for different effect sizes and power levels\n",
    "print(\"\\nSAMPLE SIZE CALCULATIONS FOR FUTURE STUDIES\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "effect_sizes = [0.2, 0.5, 0.8]  # Small, medium, large\n",
    "power_levels = [0.8, 0.9]\n",
    "\n",
    "for power in power_levels:\n",
    "    print(f\"\\nFor {power*100}% power:\")\n",
    "    for es in effect_sizes:\n",
    "        sample_size = PowerAnalysis.sample_size_t_test_independent(\n",
    "            effect_size=es, power=power, alpha=0.05\n",
    "        )\n",
    "        print(f\"  Cohen's d = {es}: n = {sample_size['total_n']} total ({sample_size['n1']} per group)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "model-diagnostics",
   "metadata": {},
   "source": [
    "## 9. Model Diagnostics and Assumptions\n",
    "\n",
    "Check statistical assumptions and model diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assumption-checks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assumption checks for regression model\n",
    "print(\"MODEL DIAGNOSTICS\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Residual analysis\n",
    "if 'model' in locals():\n",
    "    residuals = model.resid\n",
    "    fitted_values = model.fittedvalues\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Residuals vs fitted\n",
    "    axes[0, 0].scatter(fitted_values, residuals, alpha=0.6)\n",
    "    axes[0, 0].axhline(y=0, color='red', linestyle='--')\n",
    "    axes[0, 0].set_xlabel('Fitted Values')\n",
    "    axes[0, 0].set_ylabel('Residuals')\n",
    "    axes[0, 0].set_title('Residuals vs Fitted')\n",
    "    \n",
    "    # Q-Q plot\n",
    "    stats.probplot(residuals, dist=\"norm\", plot=axes[0, 1])\n",
    "    axes[0, 1].set_title('Q-Q Plot')\n",
    "    \n",
    "    # Scale-Location plot\n",
    "    standardized_residuals = residuals / np.std(residuals)\n",
    "    axes[1, 0].scatter(fitted_values, np.sqrt(np.abs(standardized_residuals)), alpha=0.6)\n",
    "    axes[1, 0].set_xlabel('Fitted Values')\n",
    "    axes[1, 0].set_ylabel('√|Standardized Residuals|')\n",
    "    axes[1, 0].set_title('Scale-Location Plot')\n",
    "    \n",
    "    # Residual histogram\n",
    "    axes[1, 1].hist(residuals, bins=20, alpha=0.7, density=True)\n",
    "    # Overlay normal curve\n",
    "    x = np.linspace(residuals.min(), residuals.max(), 100)\n",
    "    axes[1, 1].plot(x, stats.norm.pdf(x, np.mean(residuals), np.std(residuals)), 'r-', linewidth=2)\n",
    "    axes[1, 1].set_title('Residual Distribution')\n",
    "    axes[1, 1].set_ylabel('Density')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistical tests for assumptions\n",
    "    shapiro_stat, shapiro_p = stats.shapiro(residuals)\n",
    "    print(f\"Normality of residuals (Shapiro-Wilk): p = {shapiro_p:.6f}\")\n",
    "    print(f\"Residuals approximately normal: {shapiro_p > 0.05}\")\n",
    "    \n",
    "    # Homoscedasticity test (Breusch-Pagan)\n",
    "    try:\n",
    "        from statsmodels.stats.diagnostic import het_breuschpagan\n",
    "        bp_lm, bp_lm_p, bp_f, bp_f_p = het_breuschpagan(residuals, X)\n",
    "        print(f\"Homoscedasticity (Breusch-Pagan): p = {bp_lm_p:.6f}\")\n",
    "        print(f\"Constant variance assumption met: {bp_lm_p > 0.05}\")\n",
    "    except ImportError:\n",
    "        print(\"Breusch-Pagan test not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sensitivity-analysis",
   "metadata": {},
   "source": [
    "## 10. Sensitivity Analyses\n",
    "\n",
    "Test the robustness of findings through sensitivity analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sensitivity-analyses",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity analysis: Different methods and assumptions\n",
    "print(\"SENSITIVITY ANALYSES\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "sensitivity_results = []\n",
    "\n",
    "# 1. Complete case analysis (already performed)\n",
    "treatment_complete = data[data['treatment'] == 1]['continuous_outcome'].dropna()\n",
    "control_complete = data[data['treatment'] == 0]['continuous_outcome'].dropna()\n",
    "t_complete = HypothesisTests.t_test_independent(treatment_complete, control_complete)\n",
    "\n",
    "sensitivity_results.append({\n",
    "    'method': 'Complete case analysis',\n",
    "    'n_treatment': len(treatment_complete),\n",
    "    'n_control': len(control_complete),\n",
    "    'p_value': t_complete['p_value'],\n",
    "    'effect_size': t_complete['cohens_d']\n",
    "})\n",
    "\n",
    "# 2. Analysis excluding outliers (beyond 2 SD)\n",
    "outcome_mean = data['continuous_outcome'].mean()\n",
    "outcome_std = data['continuous_outcome'].std()\n",
    "outlier_threshold = 2\n",
    "\n",
    "data_no_outliers = data[\n",
    "    (data['continuous_outcome'] >= outcome_mean - outlier_threshold * outcome_std) &\n",
    "    (data['continuous_outcome'] <= outcome_mean + outlier_threshold * outcome_std)\n",
    "]\n",
    "\n",
    "treatment_no_outliers = data_no_outliers[data_no_outliers['treatment'] == 1]['continuous_outcome'].dropna()\n",
    "control_no_outliers = data_no_outliers[data_no_outliers['treatment'] == 0]['continuous_outcome'].dropna()\n",
    "\n",
    "if len(treatment_no_outliers) > 10 and len(control_no_outliers) > 10:\n",
    "    t_no_outliers = HypothesisTests.t_test_independent(treatment_no_outliers, control_no_outliers)\n",
    "    sensitivity_results.append({\n",
    "        'method': 'Excluding outliers (>2 SD)',\n",
    "        'n_treatment': len(treatment_no_outliers),\n",
    "        'n_control': len(control_no_outliers),\n",
    "        'p_value': t_no_outliers['p_value'],\n",
    "        'effect_size': t_no_outliers['cohens_d']\n",
    "    })\n",
    "\n",
    "# 3. Non-parametric test (Mann-Whitney U)\n",
    "mw_result = HypothesisTests.mann_whitney_u(treatment_complete, control_complete)\n",
    "sensitivity_results.append({\n",
    "    'method': 'Mann-Whitney U test',\n",
    "    'n_treatment': len(treatment_complete),\n",
    "    'n_control': len(control_complete),\n",
    "    'p_value': mw_result['p_value'],\n",
    "    'effect_size': mw_result['effect_size_r']\n",
    "})\n",
    "\n",
    "# Display sensitivity analysis results\n",
    "print(\"\\nSensitivity Analysis Summary:\")\n",
    "for result in sensitivity_results:\n",
    "    print(f\"\\n{result['method']}:\")\n",
    "    print(f\"  Sample sizes: Treatment n={result['n_treatment']}, Control n={result['n_control']}\")\n",
    "    print(f\"  P-value: {result['p_value']:.6f}\")\n",
    "    print(f\"  Effect size: {result['effect_size']:.4f}\")\n",
    "    print(f\"  Significant: {result['p_value'] < 0.05}\")\n",
    "\n",
    "# Check consistency of results\n",
    "significant_count = sum(1 for result in sensitivity_results if result['p_value'] < 0.05)\n",
    "print(f\"\\nConsistency check: {significant_count}/{len(sensitivity_results)} analyses significant\")\n",
    "\n",
    "if significant_count == len(sensitivity_results):\n",
    "    print(\"Results are robust across all sensitivity analyses.\")\n",
    "elif significant_count == 0:\n",
    "    print(\"No significant effect found in any sensitivity analysis.\")\n",
    "else:\n",
    "    print(\"Mixed results - findings may be sensitive to analytical choices.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "results-summary",
   "metadata": {},
   "source": [
    "## 11. Results Summary\n",
    "\n",
    "Comprehensive summary of all analyses and key findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "results-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive results table\n",
    "print(\"COMPREHENSIVE RESULTS SUMMARY\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Primary outcome results\n",
    "if 't_complete' in locals():\n",
    "    primary_result = t_complete\n",
    "    \n",
    "    print(\"\\nPRIMARY ANALYSIS RESULTS:\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"Outcome: Continuous Outcome\")\n",
    "    print(f\"Analysis: Independent samples t-test\")\n",
    "    print(f\"Sample size: n = {primary_result['group1_stats']['n'] + primary_result['group2_stats']['n']}\")\n",
    "    print(f\"Treatment group: n = {primary_result['group1_stats']['n']}, Mean = {primary_result['group1_stats']['mean']:.2f} ± {primary_result['group1_stats']['std']:.2f}\")\n",
    "    print(f\"Control group: n = {primary_result['group2_stats']['n']}, Mean = {primary_result['group2_stats']['mean']:.2f} ± {primary_result['group2_stats']['std']:.2f}\")\n",
    "    \n",
    "    mean_diff = primary_result['group1_stats']['mean'] - primary_result['group2_stats']['mean']\n",
    "    print(f\"Mean difference: {mean_diff:.2f}\")\n",
    "    print(f\"Cohen's d: {primary_result['cohens_d']:.4f}\")\n",
    "    print(f\"95% CI for difference: [{primary_result['group1_stats']['ci_lower'] - primary_result['group2_stats']['ci_upper']:.2f}, {primary_result['group1_stats']['ci_upper'] - primary_result['group2_stats']['ci_lower']:.2f}]\")\n",
    "    print(f\"T-statistic: {primary_result['t_statistic']:.4f}\")\n",
    "    print(f\"P-value: {primary_result['p_value']:.6f}\")\n",
    "    print(f\"Statistical significance: {primary_result['significant']}\")\n",
    "    \n",
    "    # Effect size interpretation\n",
    "    abs_d = abs(primary_result['cohens_d'])\n",
    "    if abs_d < 0.2:\n",
    "        effect_interpretation = \"negligible\"\n",
    "    elif abs_d < 0.5:\n",
    "        effect_interpretation = \"small\"\n",
    "    elif abs_d < 0.8:\n",
    "        effect_interpretation = \"medium\"\n",
    "    else:\n",
    "        effect_interpretation = \"large\"\n",
    "    \n",
    "    print(f\"Effect size magnitude: {effect_interpretation}\")\n",
    "    \n",
    "    # Clinical significance (if thresholds defined)\n",
    "    clinical_threshold = 5.0  # Example threshold - adjust based on your outcome\n",
    "    clinically_significant = abs(mean_diff) >= clinical_threshold\n",
    "    print(f\"Clinically meaningful difference (≥{clinical_threshold}): {clinically_significant}\")\n",
    "\n",
    "# Power analysis summary\n",
    "if 'achieved_power' in locals():\n",
    "    print(f\"\\nPOWER ANALYSIS:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(f\"Achieved power: {achieved_power:.3f} ({achieved_power*100:.1f}%)\")\n",
    "    power_adequate = achieved_power >= 0.8\n",
    "    print(f\"Adequate power (≥80%): {power_adequate}\")\n",
    "\n",
    "# Limitations and considerations\n",
    "print(f\"\\nSTATISTICAL CONSIDERATIONS:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "considerations = []\n",
    "if 'primary_result' in locals():\n",
    "    if not primary_result['group1_stats']['normal_distribution'] or not primary_result['group2_stats']['normal_distribution']:\n",
    "        considerations.append(\"Non-normal distribution detected - consider non-parametric alternatives\")\n",
    "    \n",
    "    if primary_result['group1_stats']['n'] < 30 or primary_result['group2_stats']['n'] < 30:\n",
    "        considerations.append(\"Small sample size - results should be interpreted with caution\")\n",
    "\n",
    "if 'achieved_power' in locals() and achieved_power < 0.8:\n",
    "    considerations.append(\"Statistical power < 80% - risk of Type II error\")\n",
    "\n",
    "if considerations:\n",
    "    for i, consideration in enumerate(considerations, 1):\n",
    "        print(f\"{i}. {consideration}\")\nelse:\n",
    "    print(\"No major statistical concerns identified\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "publication-table",
   "metadata": {},
   "source": [
    "## 12. Publication-Ready Tables and Figures\n",
    "\n",
    "Generate publication-quality tables and figures for manuscript submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "table1-baseline",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table 1: Baseline characteristics\n",
    "print(\"TABLE 1: BASELINE CHARACTERISTICS\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "def create_baseline_table(data):\n",
    "    \"\"\"Create a baseline characteristics table.\"\"\"\n",
    "    \n",
    "    table_data = []\n",
    "    \n",
    "    # Overall column\n",
    "    overall_col = []\n",
    "    control_col = []\n",
    "    treatment_col = []\n",
    "    p_values = []\n",
    "    \n",
    "    # Sample sizes\n",
    "    n_total = len(data)\n",
    "    n_control = len(data[data['treatment'] == 0])\n",
    "    n_treatment = len(data[data['treatment'] == 1])\n",
    "    \n",
    "    # Age\n",
    "    age_overall = DescriptiveStatistics.summary_statistics(data['age'])\n",
    "    age_control = DescriptiveStatistics.summary_statistics(data[data['treatment'] == 0]['age'])\n",
    "    age_treatment = DescriptiveStatistics.summary_statistics(data[data['treatment'] == 1]['age'])\n",
    "    age_ttest = HypothesisTests.t_test_independent(\n",
    "        data[data['treatment'] == 1]['age'],\n",
    "        data[data['treatment'] == 0]['age']\n",
    "    )\n",
    "    \n",
    "    overall_col.append(f\"{age_overall['mean']:.1f} ± {age_overall['std']:.1f}\")\n",
    "    control_col.append(f\"{age_control['mean']:.1f} ± {age_control['std']:.1f}\")\n",
    "    treatment_col.append(f\"{age_treatment['mean']:.1f} ± {age_treatment['std']:.1f}\")\n",
    "    p_values.append(age_ttest['p_value'])\n",
    "    \n",
    "    # Gender\n",
    "    gender_overall = DescriptiveStatistics.categorical_summary(data['gender'])\n",
    "    gender_control = DescriptiveStatistics.categorical_summary(data[data['treatment'] == 0]['gender'])\n",
    "    gender_treatment = DescriptiveStatistics.categorical_summary(data[data['treatment'] == 1]['gender'])\n",
    "    \n",
    "    # Chi-square test for gender\n",
    "    gender_crosstab = pd.crosstab(data['treatment'], data['gender'])\n",
    "    gender_chi2 = HypothesisTests.chi_square_test(gender_crosstab)\n",
    "    \n",
    "    # Assuming 1 = female\n",
    "    female_overall = gender_overall[gender_overall['category'] == 1]['count'].iloc[0] if len(gender_overall[gender_overall['category'] == 1]) > 0 else 0\n",
    "    female_control = gender_control[gender_control['category'] == 1]['count'].iloc[0] if len(gender_control[gender_control['category'] == 1]) > 0 else 0\n",
    "    female_treatment = gender_treatment[gender_treatment['category'] == 1]['count'].iloc[0] if len(gender_treatment[gender_treatment['category'] == 1]) > 0 else 0\n",
    "    \n",
    "    overall_col.append(f\"{female_overall} ({female_overall/n_total*100:.1f}%)\")\n",
    "    control_col.append(f\"{female_control} ({female_control/n_control*100:.1f}%)\")\n",
    "    treatment_col.append(f\"{female_treatment} ({female_treatment/n_treatment*100:.1f}%)\")\n",
    "    p_values.append(gender_chi2['p_value'])\n",
    "    \n",
    "    # Diabetes\n",
    "    diabetes_crosstab = pd.crosstab(data['treatment'], data['diabetes'])\n",
    "    diabetes_chi2 = HypothesisTests.chi_square_test(diabetes_crosstab)\n",
    "    \n",
    "    diabetes_overall = len(data[data['diabetes'] == 1])\n",
    "    diabetes_control = len(data[(data['treatment'] == 0) & (data['diabetes'] == 1)])\n",
    "    diabetes_treatment = len(data[(data['treatment'] == 1) & (data['diabetes'] == 1)])\n",
    "    \n",
    "    overall_col.append(f\"{diabetes_overall} ({diabetes_overall/n_total*100:.1f}%)\")\n",
    "    control_col.append(f\"{diabetes_control} ({diabetes_control/n_control*100:.1f}%)\")\n",
    "    treatment_col.append(f\"{diabetes_treatment} ({diabetes_treatment/n_treatment*100:.1f}%)\")\n",
    "    p_values.append(diabetes_chi2['p_value'])\n",
    "    \n",
    "    # Create table\n",
    "    baseline_table = pd.DataFrame({\n",
    "        'Characteristic': ['Age, years (mean ± SD)', 'Female gender, n (%)', 'Diabetes, n (%)'],\n",
    "        f'Overall (n={n_total})': overall_col,\n",
    "        f'Control (n={n_control})': control_col,\n",
    "        f'Treatment (n={n_treatment})': treatment_col,\n",
    "        'P-value': [f\"{p:.3f}\" if p >= 0.001 else \"<0.001\" for p in p_values]\n",
    "    })\n",
    "    \n",
    "    return baseline_table\n",
    "\n",
    "baseline_table = create_baseline_table(data)\n",
    "print(baseline_table.to_string(index=False))\n",
    "\n",
    "# Save to CSV for manuscript use\n",
    "baseline_table.to_csv('baseline_characteristics_table.csv', index=False)\n",
    "print(\"\\nBaseline table saved as 'baseline_characteristics_table.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "publication-figures",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create publication-quality figures\n",
    "print(\"\\nCREATING PUBLICATION FIGURES\")\n",
    "print(\"=\" * 35)\n",
    "\n",
    "# Set publication style\n",
    "plt.style.use('default')\n",
    "plt.rcParams.update({\n",
    "    'font.size': 12,\n",
    "    'axes.linewidth': 1.2,\n",
    "    'xtick.major.width': 1.2,\n",
    "    'ytick.major.width': 1.2,\n",
    "    'figure.dpi': 300\n",
    "})\n",
    "\n",
    "# Figure 1: Primary outcome comparison\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Box plot with individual points\n",
    "box_data = [data[data['treatment'] == 0]['continuous_outcome'].dropna(),\n",
    "            data[data['treatment'] == 1]['continuous_outcome'].dropna()]\n",
    "\n",
    "bp = ax.boxplot(box_data, labels=['Control', 'Treatment'], patch_artist=True, \n",
    "                boxprops=dict(facecolor='lightblue', alpha=0.7),\n",
    "                medianprops=dict(color='red', linewidth=2))\n",
    "\n",
    "# Add individual points with jitter\n",
    "for i, group_data in enumerate(box_data):\n",
    "    x_jitter = np.random.normal(i+1, 0.05, size=len(group_data))\n",
    "    ax.scatter(x_jitter, group_data, alpha=0.4, s=20, color='darkblue')\n",
    "\n",
    "ax.set_ylabel('Continuous Outcome')\n",
    "ax.set_xlabel('Treatment Group')\n",
    "ax.set_title('Primary Outcome by Treatment Group')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "# Add statistical annotation\n",
    "if 'primary_result' in locals():\n",
    "    y_max = max([max(group) for group in box_data])\n",
    "    ax.text(1.5, y_max * 1.1, f\"p = {primary_result['p_value']:.3f}\" if primary_result['p_value'] >= 0.001 else \"p < 0.001\",\n",
    "           ha='center', fontweight='bold')\n",
    "    ax.text(1.5, y_max * 1.05, f\"Cohen's d = {primary_result['cohens_d']:.3f}\",\n",
    "           ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('figure1_primary_outcome.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"Figure 1 saved as 'figure1_primary_outcome.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conclusions",
   "metadata": {},
   "source": [
    "## 13. Statistical Conclusions and Recommendations\n",
    "\n",
    "Final statistical interpretation and recommendations for the research team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-conclusions",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final conclusions and recommendations\n",
    "print(\"STATISTICAL CONCLUSIONS AND RECOMMENDATIONS\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(\"\\n1. PRIMARY FINDINGS:\")\n",
    "print(\"-\" * 20)\n",
    "if 'primary_result' in locals():\n",
    "    if primary_result['significant']:\n",
    "        print(f\"✓ Statistically significant treatment effect detected (p = {primary_result['p_value']:.3f})\")\n",
    "        print(f\"✓ Effect size: {effect_interpretation} (Cohen's d = {primary_result['cohens_d']:.3f})\")\n",
    "        \n",
    "        if clinically_significant:\n",
    "            print(f\"✓ Clinically meaningful difference observed (|difference| = {abs(mean_diff):.2f})\")\n",
    "        else:\n",
    "            print(f\"⚠ Statistical significance achieved but clinical meaningfulness questionable\")\n",
    "    else:\n",
    "        print(f\"✗ No statistically significant treatment effect (p = {primary_result['p_value']:.3f})\")\n",
    "        print(f\"  Effect size: {effect_interpretation} (Cohen's d = {primary_result['cohens_d']:.3f})\")\n",
    "\n",
    "print(\"\\n2. STUDY VALIDITY:\")\n",
    "print(\"-\" * 20)\n",
    "validity_issues = []\n",
    "\n",
    "# Check sample size adequacy\n",
    "if 'achieved_power' in locals():\n",
    "    if achieved_power >= 0.8:\n",
    "        print(\"✓ Adequate statistical power achieved (≥80%)\")\n",
    "    else:\n",
    "        print(f\"⚠ Insufficient statistical power ({achieved_power*100:.1f}%) - risk of Type II error\")\n",
    "        validity_issues.append(\"Underpowered study\")\n",
    "\n",
    "# Check for multiple comparisons\n",
    "if 'subgroup_results' in locals() and len(subgroup_results) > 1:\n",
    "    print(\"✓ Multiple comparisons correction applied\")\nelse:\n",
    "    print(\"ℹ Single primary comparison - no multiple testing correction needed\")\n",
    "\n",
    "# Check assumptions\n",
    "if 'primary_result' in locals():\n",
    "    if primary_result['group1_stats']['normal_distribution'] and primary_result['group2_stats']['normal_distribution']:\n",
    "        print(\"✓ Normality assumptions met for parametric testing\")\n",
    "    else:\n",
    "        print(\"⚠ Normality assumptions violated - non-parametric alternatives considered\")\n",
    "\n",
    "print(\"\\n3. RECOMMENDATIONS FOR MANUSCRIPT:\")\n",
    "print(\"-\" * 35)\n",
    "\n",
    "recommendations = [\n",
    "    \"Report both statistical and clinical significance\",\n",
    "    \"Include confidence intervals for all effect estimates\",\n",
    "    \"Present both parametric and non-parametric test results if assumptions violated\",\n",
    "    \"Acknowledge study limitations in discussion\"\n",
    "]\n",
    "\n",
    "if validity_issues:\n",
    "    recommendations.extend([\n",
    "        \"Discuss power limitations and risk of Type II error\",\n",
    "        \"Suggest appropriate sample size for future studies\"\n",
    "    ])\n",
    "\n",
    "if 'sensitivity_results' in locals():\n",
    "    recommendations.append(\"Include sensitivity analysis results to demonstrate robustness\")\n",
    "\n",
    "for i, rec in enumerate(recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")\n",
    "\n",
    "print(\"\\n4. SUGGESTED FUTURE RESEARCH:\")\n",
    "print(\"-\" * 30)\n",
    "\n",
    "future_research = []\n",
    "\n",
    "if 'achieved_power' in locals() and achieved_power < 0.8:\n",
    "    future_research.append(f\"Adequately powered replication study (n ≥ {sample_size['total_n']} for 80% power)\")\n",
    "\n",
    "if 'subgroup_results' in locals():\n",
    "    future_research.append(\"Dedicated subgroup analysis with stratified randomization\")\n",
    "\n",
    "if not clinically_significant:\n",
    "    future_research.append(\"Define minimal clinically important difference before future trials\")\n",
    "\n",
    "future_research.extend([\n",
    "    \"Longer-term follow-up to assess sustainability of effects\",\n",
    "    \"Cost-effectiveness analysis of intervention\",\n",
    "    \"Mechanistic studies to understand biological pathways\"\n",
    "])\n",
    "\n",
    "for i, research in enumerate(future_research, 1):\n",
    "    print(f\"{i}. {research}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"STATISTICAL ANALYSIS COMPLETE\")\n",
    "print(\"Analysis conducted using Medical Statistics Toolkit v1.0\")\n",
    "print(f\"Analysis date: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M')}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appendix",
   "metadata": {},
   "source": [
    "## Appendix: Analysis Log and Session Info\n",
    "\n",
    "Document the analysis environment and session details for reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "session-info",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Session information for reproducibility\n",
    "import sys\n",
    "import platform\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"ANALYSIS SESSION INFORMATION\")\n",
    "print(\"=\" * 35)\n",
    "print(f\"Analysis date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(f\"Python version: {sys.version}\")\n",
    "print(f\"Platform: {platform.system()} {platform.release()}\")\n",
    "\n",
    "# Package versions\n",
    "import importlib\n",
    "packages = ['numpy', 'pandas', 'scipy', 'matplotlib', 'seaborn', 'statsmodels', 'sklearn']\n",
    "\n",
    "print(\"\\nPackage versions:\")\n",
    "for package in packages:\n",
    "    try:\n",
    "        module = importlib.import_module(package)\n",
    "        version = getattr(module, '__version__', 'Unknown')\n",
    "        print(f\"  {package}: {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"  {package}: Not installed\")\n",
    "\n",
    "# Dataset summary\n",
    "if 'data' in locals():\n",
    "    print(f\"\\nDataset information:\")\n",
    "    print(f\"  Shape: {data.shape}\")\n",
    "    print(f\"  Missing values: {data.isnull().sum().sum()}\")\n",
    "    print(f\"  Memory usage: {data.memory_usage(deep=True).sum() / 1024:.1f} KB\")\n",
    "\n",
    "print(\"\\nAnalysis completed successfully.\")\n",
    "print(\"All results saved to working directory.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}